{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11. Training A Neural Network Model - II.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP6XjY6KiEHw5d7L5gbnYvJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanaymukherjee/Natural-Language-Processing/blob/master/11_Training_A_Neural_Network_Model_II.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xcO7tAglYbC",
        "colab_type": "text"
      },
      "source": [
        "# Training A Neural Network Model - II"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bn6Uy7z3lZ79",
        "colab_type": "text"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jGR3w6rleZC",
        "colab_type": "text"
      },
      "source": [
        "The steps of a training loop:\n",
        "1. Loop for a number of times.\n",
        "2. Shuffle the training data.\n",
        "3. Divide the data into batches.\n",
        "4. Update the model for each batch.\n",
        "5. Save the updated model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF7HOPLkk_GQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tdlh7le3lx6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create an NLP object\n",
        "from spacy.lang.en import English\n",
        "nlp = English()"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg9c04XXlzfp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the Doc class\n",
        "from spacy.tokens import Doc, Span, Token"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFm5Hvfql1dh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "2f3faf88-99a6-4967-c483-7eab43bab179"
      },
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (49.1.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.7.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQx78fXZl5yJ",
        "colab_type": "text"
      },
      "source": [
        "spaCy's rule-based Matcher is a great way to quickly create training data for named entity models. A list of sentences is available as the variable TEXTS."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mg2IkemSl95Y",
        "colab_type": "text"
      },
      "source": [
        "We want to find all mentions of different iPhone models, so we can create training data to teach a model to recognize them as 'GADGET'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amptX9Njl3vQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from spacy.matcher import Matcher\n",
        "matcher = Matcher(nlp.vocab)"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CTdCCZmmBUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXTS = ['How to preorder the iPhone X',\n",
        " 'iPhone X is coming',\n",
        " 'Should I pay $1,000 for the iPhone X?',\n",
        " 'The iPhone reviews are here',\n",
        " 'Your iPhone goes up to 11 today',\n",
        " 'I need a new phone! Any tips?']"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWNKH2jvmO8x",
        "colab_type": "text"
      },
      "source": [
        "### Building a training loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tlUpEqVmSOw",
        "colab_type": "text"
      },
      "source": [
        "Let's write a simple training loop from scratch!\n",
        "\n",
        "The pipeline you've created in the previous exercise is available as the nlp object. It already contains the entity recognizer with the added label 'GADGET'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Oqp9SWEmUGJ",
        "colab_type": "text"
      },
      "source": [
        "The small set of labelled examples that you've created previously is available as the global variable TRAINING_DATA."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EULPU5C4mXJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDriRCywmZDp",
        "colab_type": "text"
      },
      "source": [
        "Call nlp.begin_training, create a training loop for 10 iterations and shuffle the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Pm9nqQjmZyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9P2MbjFqmc5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from spacy.lang.en import English\n",
        "nlp = English()"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U60bcwLgmfA6",
        "colab_type": "text"
      },
      "source": [
        "1. Create batches of training data using spacy.util.minibatch and iterate over the batches.\n",
        "2. Convert the (text, annotations) tuples in the batch to lists of texts and annotations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sblNpoEDmh6R",
        "colab_type": "text"
      },
      "source": [
        "For each batch, use nlp.update to update the model with the texts and annotations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeKRf5BAmjVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Two tokens whose lowercase forms match 'iphone' and 'x'\n",
        "pattern3 = [{'LOWER': 'iphone'}, {'IS_DIGIT': True, 'OP': '?'}]\n",
        "\n",
        "# Add patterns to the matcher\n",
        "matcher.add('GADGET', None, pattern3)"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3_CIiASnN2g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "5052f950-5bb3-47ef-8c74-13af2092bb2a"
      },
      "source": [
        "# Create a Doc object for each text in TEXTS\n",
        "for doc in nlp.pipe(TEXTS):\n",
        "    # Find the matches in the doc\n",
        "    matches = matcher(doc)\n",
        "    \n",
        "    # Get a list of (start, end, label) tuples of matches in the text\n",
        "    entities = [(start, end, 'GADGET') for match_id, start, end in matches]\n",
        "    print(doc.text, entities)    "
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "How to preorder the iPhone X [(4, 5, 'GADGET')]\n",
            "iPhone X is coming [(0, 1, 'GADGET')]\n",
            "Should I pay $1,000 for the iPhone X? [(7, 8, 'GADGET')]\n",
            "The iPhone reviews are here [(1, 2, 'GADGET')]\n",
            "Your iPhone goes up to 11 today [(1, 2, 'GADGET')]\n",
            "I need a new phone! Any tips? []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzXX2FBamvZp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "1ac4c126-3c45-4f08-e243-2089615f3e39"
      },
      "source": [
        "TRAINING_DATA = []\n",
        "\n",
        "# Create a Doc object for each text in TEXTS\n",
        "for doc in nlp.pipe(TEXTS):\n",
        "    # Match on the doc and create a list of matched spans\n",
        "    spans = [doc[start:end] for match_id, start, end in matcher(doc)]\n",
        "    # Get (start character, end character, label) tuples of matches\n",
        "    entities = [(span.start_char, span.end_char, 'GADGET') for span in spans]\n",
        "    \n",
        "    # Format the matches as a (doc.text, entities) tuple\n",
        "    training_example = (doc.text, {'entities': entities})\n",
        "    # Append the example to the training data\n",
        "    TRAINING_DATA.append(training_example)\n",
        "    \n",
        "print(*TRAINING_DATA, sep='\\n')    "
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('How to preorder the iPhone X', {'entities': [(20, 26, 'GADGET')]})\n",
            "('iPhone X is coming', {'entities': [(0, 6, 'GADGET')]})\n",
            "('Should I pay $1,000 for the iPhone X?', {'entities': [(28, 34, 'GADGET')]})\n",
            "('The iPhone reviews are here', {'entities': [(4, 10, 'GADGET')]})\n",
            "('Your iPhone goes up to 11 today', {'entities': [(5, 11, 'GADGET')]})\n",
            "('I need a new phone! Any tips?', {'entities': []})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDvUOrxAlknh",
        "colab_type": "text"
      },
      "source": [
        "### Setting up the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cN-kg2ejmJMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a blank 'en' model\n",
        "nlp = spacy.blank('en')"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHcqz1EmmKbp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a new entity recognizer and add it to the pipeline\n",
        "ner = nlp.create_pipe('ner')\n",
        "nlp.add_pipe(ner)"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDoxcdfumL_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add the label 'GADGET' to the entity recognizer\n",
        "ner.add_label('GADGET')"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XU2-b_OnBDx",
        "colab_type": "text"
      },
      "source": [
        "Call nlp.begin_training, create a training loop for 10 iterations and shuffle the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91JAOkaymruZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start the training\n",
        "nlp.begin_training()\n",
        "\n",
        "# Loop for 10 iterations\n",
        "for itn in range(10):\n",
        "    # Shuffle the training data\n",
        "    random.shuffle(TRAINING_DATA)"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hz4dmSDDm-Ch",
        "colab_type": "text"
      },
      "source": [
        "1. Create batches of training data using spacy.util.minibatch and iterate over the batches.\n",
        "2. Convert the (text, annotations) tuples in the batch to lists of texts and annotations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyj5DEP1m13g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start the training\n",
        "nlp.begin_training()\n",
        "\n",
        "# Loop for 10 iterations\n",
        "for itn in range(10):\n",
        "    # Shuffle the training data\n",
        "    random.shuffle(TRAINING_DATA)\n",
        "    losses = {}\n",
        "    \n",
        "    # Batch the examples and iterate over them\n",
        "    for batch in spacy.util.minibatch(TRAINING_DATA, size=2):\n",
        "        texts = [text for text, entities in batch]\n",
        "        annotations = [entities for text, entities in batch]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwYEKEKym7_q",
        "colab_type": "text"
      },
      "source": [
        "For each batch, use nlp.update to update the model with the texts and annotations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG_cOIG0m4Xi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "f0d28d11-78f3-4ee4-954e-653b9fb49047"
      },
      "source": [
        "# Start the training\n",
        "nlp.begin_training()\n",
        "\n",
        "# Loop for 10 iterations\n",
        "for itn in range(10):\n",
        "    # Shuffle the training data\n",
        "    random.shuffle(TRAINING_DATA)\n",
        "    losses = {}\n",
        "    \n",
        "    # Batch the examples and iterate over them\n",
        "    for batch in spacy.util.minibatch(TRAINING_DATA, size=2):\n",
        "        texts = [text for text, entities in batch]\n",
        "        annotations = [entities for text, entities in batch]\n",
        "        \n",
        "        # Update the model\n",
        "        nlp.update(texts, annotations, losses=losses)\n",
        "        print(losses)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'ner': 10.0}\n",
            "{'ner': 21.905810594558716}\n",
            "{'ner': 32.25822949409485}\n",
            "{'ner': 10.269250392913818}\n",
            "{'ner': 15.439290881156921}\n",
            "{'ner': 19.906322598457336}\n",
            "{'ner': 2.8490229845046997}\n",
            "{'ner': 4.489939351100475}\n",
            "{'ner': 7.512486565625295}\n",
            "{'ner': 2.6266299698036164}\n",
            "{'ner': 3.5055149205436464}\n",
            "{'ner': 4.419238194212085}\n",
            "{'ner': 0.3983194096945226}\n",
            "{'ner': 0.48387045215349644}\n",
            "{'ner': 0.6165173742047045}\n",
            "{'ner': 0.017605453482246958}\n",
            "{'ner': 0.01866214360052254}\n",
            "{'ner': 0.021317225425036668}\n",
            "{'ner': 0.00020233733502550422}\n",
            "{'ner': 0.00020756504967778255}\n",
            "{'ner': 0.0002859472314993283}\n",
            "{'ner': 2.7428648396998767e-07}\n",
            "{'ner': 1.4316221002721227e-05}\n",
            "{'ner': 1.4523199756152818e-05}\n",
            "{'ner': 1.8436688343933622e-06}\n",
            "{'ner': 1.8478045194204412e-06}\n",
            "{'ner': 1.8513102033167448e-06}\n",
            "{'ner': 1.127002382804882e-09}\n",
            "{'ner': 1.0077552362912969e-08}\n",
            "{'ner': 3.1408443326034474e-08}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbgIxZ6W7V9Q",
        "colab_type": "text"
      },
      "source": [
        "### Exploring the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YinJtA-37eCR",
        "colab_type": "text"
      },
      "source": [
        "Let's see how the model performs on unseen data! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdpi5rmc7gut",
        "colab_type": "text"
      },
      "source": [
        "1. Process each text in TEST_DATA using nlp.pipe.\n",
        "2. Print the document text and the entities in the text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AshrGY4M7WWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEST_DATA = ['Apple is slowing down the iPhone 8 and iPhone X - how to stop it',\n",
        " \"I finally understand what the iPhone X 'notch' is for\",\n",
        " 'Everything you need to know about the Samsung Galaxy S9',\n",
        " 'Looking to compare iPad models? Hereâ€™s how the 2018 lineup stacks up',\n",
        " 'The iPhone 8 and iPhone 8 Plus are smartphones designed, developed, and marketed by Apple',\n",
        " 'what is the cheapest ipad, especially ipad pro???',\n",
        " 'Samsung Galaxy is a series of mobile computing devices designed, manufactured and marketed by Samsung Electronics']"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqaUzRMH7RhE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "5a1600e8-1b04-47ac-ca9b-287f6d1b7197"
      },
      "source": [
        "# Process each text in TEST_DATA\n",
        "for doc in nlp.pipe(TEST_DATA):\n",
        "    # Print the document text and entitites\n",
        "    print(doc.text)\n",
        "    print(doc.ents, '\\n\\n')"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Apple is slowing down the iPhone 8 and iPhone X - how to stop it\n",
            "(iPhone, iPhone) \n",
            "\n",
            "\n",
            "I finally understand what the iPhone X 'notch' is for\n",
            "(iPhone,) \n",
            "\n",
            "\n",
            "Everything you need to know about the Samsung Galaxy S9\n",
            "() \n",
            "\n",
            "\n",
            "Looking to compare iPad models? Hereâ€™s how the 2018 lineup stacks up\n",
            "() \n",
            "\n",
            "\n",
            "The iPhone 8 and iPhone 8 Plus are smartphones designed, developed, and marketed by Apple\n",
            "(iPhone, iPhone) \n",
            "\n",
            "\n",
            "what is the cheapest ipad, especially ipad pro???\n",
            "() \n",
            "\n",
            "\n",
            "Samsung Galaxy is a series of mobile computing devices designed, manufactured and marketed by Samsung Electronics\n",
            "() \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}