{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07. Processing Pipelines.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPp084f1+I0z6WwN1Surspv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanaymukherjee/Natural-Language-Processing/blob/master/07_Processing_Pipelines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSuTLYt6aEHM",
        "colab_type": "text"
      },
      "source": [
        "# Processing Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMmWgYg_cke8",
        "colab_type": "text"
      },
      "source": [
        "## Inspecting the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wteoPBiUcOd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create an NLP object\n",
        "from spacy.lang.en import English\n",
        "nlp = English()"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lp3ZW-icOYK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the Doc class\n",
        "from spacy.tokens import Doc, Span"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_3WMNojcRTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDOVTAdncX3c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "33c1ea6b-2dda-4a1c-acdf-33bb3edaf5fb"
      },
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.7.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (49.1.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oapK1B5HZ_wZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "9d8909e4-f87c-439b-fcdf-244912db7d73"
      },
      "source": [
        "# Load the en_core_web_sm model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Print the names of the pipeline components\n",
        "print(nlp.pipe_names)\n",
        "\n",
        "# Print the full pipeline of (name, component) tuples\n",
        "print(nlp.pipeline)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['tagger', 'parser', 'ner']\n",
            "[('tagger', <spacy.pipeline.pipes.Tagger object at 0x7f18b2473da0>), ('parser', <spacy.pipeline.pipes.DependencyParser object at 0x7f18af891d68>), ('ner', <spacy.pipeline.pipes.EntityRecognizer object at 0x7f18af891dc8>)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nI_H6d1Hcgr7",
        "colab_type": "text"
      },
      "source": [
        "## Custom pipeline components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyKrPeQ5dt0i",
        "colab_type": "text"
      },
      "source": [
        "### Simple components"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lk0zAkKlcgSF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a4619aae-5621-444c-869b-56adc457963a"
      },
      "source": [
        "# Define the custom component\n",
        "def length_component(doc):\n",
        "    # Get the doc's length\n",
        "    doc_length = len(doc)\n",
        "    print(\"This document is {} tokens long.\".format(doc_length))\n",
        "    # Return the doc\n",
        "    return doc\n",
        "\n",
        "# Load the small English model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Add the component first in the pipeline and print the pipe names\n",
        "nlp.add_pipe(length_component, first=True)\n",
        "print(nlp.pipe_names)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['length_component', 'tagger', 'parser', 'ner']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtnJGUOXdjiI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c6aa7d1b-6104-4c5e-ab09-8b75b4b8b48b"
      },
      "source": [
        "# Load the small English model and Add the component first in the pipeline\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "nlp.add_pipe(length_component, first=True)\n",
        "\n",
        "# Process a text\n",
        "doc = nlp(\"This is a sentence.\")"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This document is 5 tokens long.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQp6zOWYdpby",
        "colab_type": "text"
      },
      "source": [
        "### Complex components"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNA5mWQXHHYi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ad123698-b8bb-4dac-fdfd-8acbad763b65"
      },
      "source": [
        "# Load the small English model and Add the component first in the pipeline\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "nlp.add_pipe(length_component, first=True)\n",
        "\n",
        "# Process a text\n",
        "doc = nlp(\"I have a cat and a Golden Retriever\")"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This document is 8 tokens long.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLtGYD4Xdvky",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ca5f927b-2410-4dae-f2e0-246bb2f4b1d2"
      },
      "source": [
        "# Define the custom component\n",
        "def animal_component(doc):\n",
        "    # Apply the matcher to the doc\n",
        "    matches = matcher(doc)\n",
        "    # Create a Span for each match and assign the label 'ANIMAL'\n",
        "    spans = [Span(doc, start, end, label='ANIMAL')\n",
        "             for match_id, start, end in matches]\n",
        "    # Overwrite the doc.ents with the matched spans\n",
        "    doc.ents = spans\n",
        "    return doc\n",
        "\n",
        "# Add the component to the pipeline after the 'ner' component \n",
        "nlp.add_pipe(animal_component, after='ner')\n",
        "print(nlp.pipe_names)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['length_component', 'tagger', 'parser', 'ner', 'animal_component']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96HWDSuIdA-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from spacy.matcher import Matcher\n",
        "matcher = Matcher(nlp.vocab)"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cHC46vnGh4z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the match patterns\n",
        "pattern1 = [{'LOWER': 'Golden'}, {'IS_TITLE': True, 'POS': 'NOUN'}]\n",
        "pattern2 = [{'LOWER': 'Cat'}, {'TEXT': '-'}, {'LOWER': 'free'}, {'POS': 'NOUN'}]\n",
        "\n",
        "# Initialize the Matcher and add the patterns\n",
        "matcher = Matcher(nlp.vocab)\n",
        "matcher.add('PATTERN1', None, pattern1)\n",
        "matcher.add('PATTERN2', None, pattern2)\n",
        "\n",
        "# Iterate over the matches\n",
        "for match_id, start, end in matcher(doc):\n",
        "    # Print pattern string name and text of matched span\n",
        "    print(doc.vocab.strings[match_id], doc[start:end].text)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mD1WzP4aeQCe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2d5d8d12-720d-478f-b163-f8a5f1d76c43"
      },
      "source": [
        "# import necessary modules\n",
        "import spacy\n",
        "#import PhraseMatcher class\n",
        "from spacy.matcher import PhraseMatcher\n",
        "\n",
        "# Language class with the English model 'en_core_web_sm' is loaded\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# create the PhraseMatcher object\n",
        "matcher = PhraseMatcher(nlp.vocab, attr='LOWER')\n",
        "\n",
        "# the list containing the pharses to be matched\n",
        "terminology_list = [\"Golden Retriever\", \"Cat\"]\n",
        "\n",
        "# convert the phrases into document object using nlp.make_doc to #speed up.\n",
        "patterns = [nlp.make_doc(text) for text in terminology_list]\n",
        "# add the patterns to the matcher object without any callbacks\n",
        "matcher.add(\"Phrase Matching\", None, *patterns)\n",
        "# the input text string is converted to a Document object\n",
        "doc = nlp(\"I have a cat and a Golden Retriever\")\n",
        "\n",
        "#call the matcher object the document object and it will return #match_id, start and stop indexes of the matched words\n",
        "matches = matcher(doc)\n",
        "#print the matched results and extract out the results\n",
        "for match_id, start, end in matches:\n",
        "    # Get the string representation \n",
        "    string_id = nlp.vocab.strings[match_id]  \n",
        "    span = doc[start:end]  # The matched span\n",
        "    print(match_id, string_id, start, end, span.text)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11356100181062323261 Phrase Matching 3 4 cat\n",
            "11356100181062323261 Phrase Matching 6 8 Golden Retriever\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuUM7KTEfJ_c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fac9a96a-181a-449f-e6d1-3d7ef70a05ad"
      },
      "source": [
        "# import necessary packages and tools \n",
        "import spacy\n",
        "from spacy.pipeline import EntityRuler # import EntityRuler \n",
        "# load a blank English model from spacy\n",
        "nlp = spacy.blank('en')\n",
        "# convert the input sentence into the document object \n",
        "doc = nlp(\"I have a cat and a Golden Retriever\")\n",
        "# print the entity types of each entity in the above sentence\n",
        "print([(ent.text, ent.label_) for ent in doc.ents])"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9HVCiHKfmrt",
        "colab_type": "text"
      },
      "source": [
        "We have imported the EntityRuler matcher and the spaCy blank English model and got the input string converted into a document object. Then we have printed the entity types of each entity available in the input. In this case, it retrieves nothing but an empty list because it is a blank model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjJp60FDf828",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2a92a67c-5d1a-4883-c41f-40ea5619ff67"
      },
      "source": [
        "# instantiate an object of EntityRuler class\n",
        "ruler = EntityRuler(nlp)\n",
        "# define the pattern\n",
        "patterns = [{\"label\": \"ANIMAL\", \"pattern\": \"Golden Retriever\"}]\n",
        "\n",
        "# add the pattern to the matcher object\n",
        "ruler.add_patterns(patterns)\n",
        "\n",
        "# add the matcher object as a new pipe to the model\n",
        "nlp.add_pipe(ruler)\n",
        "# convert the input sentence into the document object using the newly added 'nlp'\n",
        "doc = nlp(\"I have a cat and a Golden Retriever\")\n",
        "# print the entities in the sentenced after adding the EntityRuler matcher\n",
        "print([(ent.text, ent.label_) for ent in doc.ents])"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Golden Retriever', 'ANIMAL')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou3NypjLhW4C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the PhraseMatcher and initialize it\n",
        "from spacy.matcher import PhraseMatcher\n",
        "matcher = PhraseMatcher(nlp.vocab)"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHNwGABAhr9A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8fd1edaa-e6bd-4826-ba89-e9dac9a1b006"
      },
      "source": [
        "# Create a doc from the words and spaces\n",
        "doc = Doc(nlp.vocab, words=['Golden Retriever', 'cat', 'turtle', 'dog'], spaces=[True, True, True, False])\n",
        "\n",
        "# Create a span for \"Rafeal Nadal\" from the doc and assign it the label \"PERSON\"\n",
        "span = Span(doc, 0, 1, label='Animal')\n",
        "print(span.text, span.label_)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Golden Retriever Animal\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SshkaXlYd-yy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "20135f31-1ae9-43eb-ec0a-c9339dc6c1bc"
      },
      "source": [
        "# Process the text and print the text and label for the doc.ents\n",
        "doc = nlp(\"I have a cat and a Golden Retriever\")\n",
        "print([(ent.text, ent.label_) for ent in doc.ents])"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Golden Retriever', 'ANIMAL')]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}